{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vLLM을 활용한 LLM Agent Serving 튜토리얼\n",
    "\n",
    "### 에이전트 아키텍처\n",
    "\n",
    "본 튜토리얼에서 구현할 에이전트는 다음 요소들로 구성된다:\n",
    "- **Pydantic**: 강력한 타입 검증 및 스키마 정의\n",
    "- **Function Calling & Tool**: OpenAI 스타일 function calling 지원\n",
    "- **Memory**: 효율적인 대화 컨텍스트 관리\n",
    "- **Validation**: 입출력 데이터 무결성 보장\n",
    "- **Recovery**: 장애 복구 및 재시도 로직\n",
    "- **Feedback**: 성능 모니터링 및 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q asyncio aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional, Callable, Union\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pydantic 스키마 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321893/3717748012.py:13: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  class ToolDefinition(BaseModel):\n",
      "/tmp/ipykernel_321893/3717748012.py:31: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  @validator('role')\n"
     ]
    }
   ],
   "source": [
    "class FunctionParameter(BaseModel):\n",
    "    \"\"\"Function calling의 파라미터를 정의하는 모델이다\"\"\"\n",
    "    type: str = Field(description=\"파라미터 타입\")\n",
    "    description: str = Field(description=\"파라미터 설명\")\n",
    "    enum: Optional[List[str]] = Field(default=None, description=\"가능한 값들의 목록\")\n",
    "\n",
    "class FunctionDefinition(BaseModel):\n",
    "    \"\"\"OpenAI 스타일 function 정의를 표현하는 모델이다\"\"\"\n",
    "    name: str = Field(description=\"함수 이름\")\n",
    "    description: str = Field(description=\"함수 기능 설명\")\n",
    "    parameters: Dict[str, Any] = Field(description=\"함수 파라미터 스키마\")\n",
    "    \n",
    "class ToolDefinition(BaseModel):\n",
    "    \"\"\"에이전트가 사용할 도구를 정의하는 모델이다\"\"\"\n",
    "    type: str = Field(default=\"function\", description=\"도구 타입\")\n",
    "    function: FunctionDefinition = Field(description=\"함수 정의\")\n",
    "    callable: Callable = Field(description=\"실제 실행할 함수\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"대화 메시지를 표현하는 모델이다\"\"\"\n",
    "    role: str = Field(description=\"메시지 역할: system, user, assistant, tool\")\n",
    "    content: Optional[str] = Field(default=None, description=\"메시지 내용\")\n",
    "    tool_calls: Optional[List[Dict[str, Any]]] = Field(default=None, description=\"도구 호출 정보\")\n",
    "    tool_call_id: Optional[str] = Field(default=None, description=\"도구 호출 ID\")\n",
    "    name: Optional[str] = Field(default=None, description=\"도구 이름\")\n",
    "    timestamp: datetime = Field(default_factory=datetime.now, description=\"메시지 생성 시간\")\n",
    "    \n",
    "    @validator('role')\n",
    "    def validate_role(cls, v):\n",
    "        \"\"\"역할이 유효한 값인지 검증한다\"\"\"\n",
    "        allowed_roles = ['system', 'user', 'assistant', 'tool']\n",
    "        assert v in allowed_roles, f\"역할은 {allowed_roles} 중 하나여야 한다\"\n",
    "        return v\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    \"\"\"에이전트의 응답을 표현하는 모델이다\"\"\"\n",
    "    content: str = Field(description=\"응답 내용\")\n",
    "    tool_calls: Optional[List[Dict[str, Any]]] = Field(default=None, description=\"실행된 도구 정보\")\n",
    "    total_tokens: int = Field(default=0, description=\"사용된 총 토큰 수\")\n",
    "    latency_ms: float = Field(default=0.0, description=\"응답 지연 시간\")\n",
    "    is_successful: bool = Field(default=True, description=\"응답 성공 여부\")\n",
    "    error_message: Optional[str] = Field(default=None, description=\"오류 메시지\")\n",
    "\n",
    "class ValidationResult(BaseModel):\n",
    "    \"\"\"검증 결과를 표현하는 모델이다\"\"\"\n",
    "    is_valid: bool = Field(description=\"검증 통과 여부\")\n",
    "    error_message: Optional[str] = Field(default=None, description=\"검증 실패 메시지\")\n",
    "    validation_details: Dict[str, Any] = Field(default_factory=dict, description=\"상세 검증 정보\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationMemory:\n",
    "    \"\"\"대화 기록을 관리하고 컨텍스트 윈도우를 최적화하는 메모리 시스템이다\"\"\"\n",
    "    \n",
    "    def __init__(self, max_tokens: int = 4096, max_messages: int = 100):\n",
    "        \"\"\"최대 토큰 수와 메시지 수를 설정하여 초기화한다\"\"\"\n",
    "        self.messages: List[Message] = []\n",
    "        self.max_tokens = max_tokens\n",
    "        self.max_messages = max_messages\n",
    "        self.system_message: Optional[Message] = None\n",
    "    \n",
    "    def set_system_message(self, content: str) -> None:\n",
    "        \"\"\"시스템 메시지를 설정한다\"\"\"\n",
    "        self.system_message = Message(role=\"system\", content=content)\n",
    "    \n",
    "    def add_message(self, role: str, content: Optional[str] = None, \n",
    "                   tool_calls: Optional[List[Dict]] = None,\n",
    "                   tool_call_id: Optional[str] = None,\n",
    "                   name: Optional[str] = None) -> None:\n",
    "        \"\"\"새로운 메시지를 메모리에 추가한다\"\"\"\n",
    "        message = Message(\n",
    "            role=role,\n",
    "            content=content,\n",
    "            tool_calls=tool_calls,\n",
    "            tool_call_id=tool_call_id,\n",
    "            name=name\n",
    "        )\n",
    "        self.messages.append(message)\n",
    "        self._trim_messages()\n",
    "    \n",
    "    def _trim_messages(self) -> None:\n",
    "        \"\"\"메시지 수가 한계를 초과하면 오래된 메시지를 제거한다\"\"\"\n",
    "        while len(self.messages) > self.max_messages:\n",
    "            self.messages.pop(0)\n",
    "    \n",
    "    def get_messages(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"OpenAI API 형식으로 메시지 리스트를 반환한다\"\"\"\n",
    "        result = []\n",
    "        \n",
    "        if self.system_message:\n",
    "            result.append({\"role\": \"system\", \"content\": self.system_message.content})\n",
    "        \n",
    "        for msg in self.messages:\n",
    "            msg_dict = {\"role\": msg.role}\n",
    "            \n",
    "            if msg.content:\n",
    "                msg_dict[\"content\"] = msg.content\n",
    "            if msg.tool_calls:\n",
    "                msg_dict[\"tool_calls\"] = msg.tool_calls\n",
    "            if msg.tool_call_id:\n",
    "                msg_dict[\"tool_call_id\"] = msg.tool_call_id\n",
    "            if msg.name:\n",
    "                msg_dict[\"name\"] = msg.name\n",
    "            \n",
    "            result.append(msg_dict)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"대화 기록을 초기화한다\"\"\"\n",
    "        self.messages.clear()\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"메모리 통계 정보를 반환한다\"\"\"\n",
    "        role_counts = {}\n",
    "        for msg in self.messages:\n",
    "            role_counts[msg.role] = role_counts.get(msg.role, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_messages\": len(self.messages),\n",
    "            \"role_distribution\": role_counts,\n",
    "            \"has_system_message\": self.system_message is not None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function Calling & Tool 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 도구 함수들을 정의한다\n",
    "\n",
    "def get_current_time(timezone: str = \"UTC\") -> str:\n",
    "    \"\"\"현재 시간을 반환한다\"\"\"\n",
    "    current_time = datetime.now()\n",
    "    return f\"{timezone} 기준 현재 시간: {current_time.strftime('%Y-%m-%d %H:%M:%S')}다\"\n",
    "\n",
    "def calculate_advanced(expression: str) -> str:\n",
    "    \"\"\"수학 표현식을 계산한다\"\"\"\n",
    "    result = eval(expression)\n",
    "    return f\"계산 결과: {expression} = {result}다\"\n",
    "\n",
    "def query_knowledge_base(topic: str, detail_level: str = \"medium\") -> str:\n",
    "    \"\"\"지식 베이스에서 정보를 조회한다\"\"\"\n",
    "    knowledge = {\n",
    "        \"python\": \"Python은 고수준 프로그래밍 언어다\",\n",
    "        \"ai\": \"인공지능은 기계가 인간의 지능을 모방하는 기술이다\",\n",
    "        \"vllm\": \"vLLM은 고성능 LLM 추론 엔진이다\"\n",
    "    }\n",
    "    info = knowledge.get(topic.lower(), f\"{topic}에 대한 정보를 찾을 수 없다\")\n",
    "    return f\"[{detail_level} 수준] {info}\"\n",
    "\n",
    "def execute_database_query(query: str, limit: int = 10) -> str:\n",
    "    \"\"\"데이터베이스 쿼리를 실행한다\"\"\"\n",
    "    return f\"쿼리 '{query}' 실행 완료: {limit}개의 결과를 반환했다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolManager:\n",
    "    \"\"\"도구들을 관리하고 실행하는 매니저다\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"도구 매니저를 초기화한다\"\"\"\n",
    "        self.tools: Dict[str, ToolDefinition] = {}\n",
    "        self.execution_history: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def register_tool(self, tool: ToolDefinition) -> None:\n",
    "        \"\"\"새로운 도구를 등록한다\"\"\"\n",
    "        self.tools[tool.function.name] = tool\n",
    "    \n",
    "    def get_tool_schemas(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"OpenAI API 형식의 도구 스키마를 반환한다\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"type\": tool.type,\n",
    "                \"function\": {\n",
    "                    \"name\": tool.function.name,\n",
    "                    \"description\": tool.function.description,\n",
    "                    \"parameters\": tool.function.parameters\n",
    "                }\n",
    "            }\n",
    "            for tool in self.tools.values()\n",
    "        ]\n",
    "    \n",
    "    def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"도구를 실행하고 결과를 반환한다\"\"\"\n",
    "        tool = self.tools.get(tool_name)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = tool.callable(**arguments)\n",
    "        execution_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # 실행 기록을 저장한다\n",
    "        self.execution_history.append({\n",
    "            \"tool_name\": tool_name,\n",
    "            \"arguments\": arguments,\n",
    "            \"result\": result,\n",
    "            \"execution_time_ms\": execution_time,\n",
    "            \"timestamp\": datetime.now()\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_tool(self, name: str) -> Optional[ToolDefinition]:\n",
    "        \"\"\"이름으로 도구를 검색한다\"\"\"\n",
    "        return self.tools.get(name)\n",
    "    \n",
    "    def get_execution_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"도구 실행 통계를 반환한다\"\"\"\n",
    "        if not self.execution_history:\n",
    "            return {\"total_executions\": 0}\n",
    "        \n",
    "        tool_counts = {}\n",
    "        total_time = 0\n",
    "        \n",
    "        for execution in self.execution_history:\n",
    "            tool_name = execution[\"tool_name\"]\n",
    "            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n",
    "            total_time += execution[\"execution_time_ms\"]\n",
    "        \n",
    "        return {\n",
    "            \"total_executions\": len(self.execution_history),\n",
    "            \"tool_usage\": tool_counts,\n",
    "            \"average_execution_time_ms\": total_time / len(self.execution_history)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputValidator:\n",
    "    \"\"\"입력 데이터를 검증하는 클래스다\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_message(content: str) -> ValidationResult:\n",
    "        \"\"\"메시지 내용의 유효성을 검증한다\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        if not content or not content.strip():\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                error_message=\"메시지가 비어있다\",\n",
    "                validation_details={\"content_length\": 0}\n",
    "            )\n",
    "        \n",
    "        content_length = len(content)\n",
    "        details[\"content_length\"] = content_length\n",
    "        \n",
    "        if content_length > 50000:\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                error_message=f\"메시지가 너무 길다 (최대 50000자, 현재 {content_length}자)\",\n",
    "                validation_details=details\n",
    "            )\n",
    "        \n",
    "        return ValidationResult(is_valid=True, validation_details=details)\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_tool_arguments(tool: ToolDefinition, arguments: Dict[str, Any]) -> ValidationResult:\n",
    "        \"\"\"도구 호출의 인자를 검증한다\"\"\"\n",
    "        details = {\"provided_arguments\": list(arguments.keys())}\n",
    "        \n",
    "        required_params = tool.function.parameters.get(\"required\", [])\n",
    "        details[\"required_parameters\"] = required_params\n",
    "        \n",
    "        for param in required_params:\n",
    "            if param not in arguments:\n",
    "                return ValidationResult(\n",
    "                    is_valid=False,\n",
    "                    error_message=f\"필수 파라미터 '{param}'가 누락되었다\",\n",
    "                    validation_details=details\n",
    "                )\n",
    "        \n",
    "        return ValidationResult(is_valid=True, validation_details=details)\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_response(response: Dict[str, Any]) -> ValidationResult:\n",
    "        \"\"\"모델 응답의 유효성을 검증한다\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        if \"choices\" not in response:\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                error_message=\"응답에 'choices' 필드가 없다\",\n",
    "                validation_details=details\n",
    "            )\n",
    "        \n",
    "        if not response[\"choices\"]:\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                error_message=\"응답의 choices가 비어있다\",\n",
    "                validation_details=details\n",
    "            )\n",
    "        \n",
    "        details[\"num_choices\"] = len(response[\"choices\"])\n",
    "        return ValidationResult(is_valid=True, validation_details=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recovery 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecoveryStrategy:\n",
    "    \"\"\"오류 발생 시 복구 전략을 관리하는 클래스다\"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, retry_delay: float = 1.0):\n",
    "        \"\"\"복구 전략을 초기화한다\"\"\"\n",
    "        self.max_retries = max_retries\n",
    "        self.retry_delay = retry_delay\n",
    "        self.failure_log: List[Dict[str, Any]] = []\n",
    "        self.recovery_attempts: Dict[str, int] = {}\n",
    "    \n",
    "    def log_failure(self, error_type: str, error_message: str, \n",
    "                   context: Dict[str, Any]) -> None:\n",
    "        \"\"\"실패 사례를 로그에 기록한다\"\"\"\n",
    "        self.failure_log.append({\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"error_type\": error_type,\n",
    "            \"error_message\": error_message,\n",
    "            \"context\": context\n",
    "        })\n",
    "    \n",
    "    def should_retry(self, operation_id: str) -> bool:\n",
    "        \"\"\"재시도 가능 여부를 판단한다\"\"\"\n",
    "        current_attempts = self.recovery_attempts.get(operation_id, 0)\n",
    "        return current_attempts < self.max_retries\n",
    "    \n",
    "    def record_retry(self, operation_id: str) -> int:\n",
    "        \"\"\"재시도를 기록하고 현재 시도 횟수를 반환한다\"\"\"\n",
    "        self.recovery_attempts[operation_id] = self.recovery_attempts.get(operation_id, 0) + 1\n",
    "        return self.recovery_attempts[operation_id]\n",
    "    \n",
    "    def reset_operation(self, operation_id: str) -> None:\n",
    "        \"\"\"작업의 재시도 카운터를 초기화한다\"\"\"\n",
    "        if operation_id in self.recovery_attempts:\n",
    "            del self.recovery_attempts[operation_id]\n",
    "    \n",
    "    def get_fallback_response(self, error_type: str) -> str:\n",
    "        \"\"\"오류 타입에 따른 폴백 응답을 생성한다\"\"\"\n",
    "        fallback_messages = {\n",
    "            \"tool_execution_error\": \"도구 실행에 실패했다. 다른 방법으로 질문에 답변하겠다.\",\n",
    "            \"validation_error\": \"입력 검증에 실패했다. 올바른 형식으로 다시 질문해 달라.\",\n",
    "            \"api_error\": \"API 호출에 실패했다. 잠시 후 다시 시도해 달라.\",\n",
    "            \"timeout_error\": \"응답 시간이 초과되었다. 더 간단한 질문으로 다시 시도해 달라.\"\n",
    "        }\n",
    "        return fallback_messages.get(error_type, \"예상치 못한 오류가 발생했다.\")\n",
    "    \n",
    "    def get_recovery_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"복구 통계 정보를 반환한다\"\"\"\n",
    "        error_type_counts = {}\n",
    "        for failure in self.failure_log:\n",
    "            error_type = failure[\"error_type\"]\n",
    "            error_type_counts[error_type] = error_type_counts.get(error_type, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_failures\": len(self.failure_log),\n",
    "            \"error_distribution\": error_type_counts,\n",
    "            \"active_retries\": len(self.recovery_attempts)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feedback 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMonitor:\n",
    "    \"\"\"에이전트의 성능을 모니터링하고 피드백을 수집하는 클래스다\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"성능 모니터를 초기화한다\"\"\"\n",
    "        self.response_times: List[float] = []\n",
    "        self.token_usage: List[int] = []\n",
    "        self.user_feedback: List[Dict[str, Any]] = []\n",
    "        self.quality_scores: List[float] = []\n",
    "    \n",
    "    def record_response(self, latency_ms: float, tokens: int) -> None:\n",
    "        \"\"\"응답 메트릭을 기록한다\"\"\"\n",
    "        self.response_times.append(latency_ms)\n",
    "        self.token_usage.append(tokens)\n",
    "    \n",
    "    def add_user_feedback(self, query: str, response: str, \n",
    "                         rating: float, comment: str = \"\") -> None:\n",
    "        \"\"\"사용자 피드백을 추가한다\"\"\"\n",
    "        feedback = {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"rating\": rating,\n",
    "            \"comment\": comment\n",
    "        }\n",
    "        self.user_feedback.append(feedback)\n",
    "        self.quality_scores.append(rating)\n",
    "    \n",
    "    def get_performance_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"성능 메트릭 요약을 반환한다\"\"\"\n",
    "        metrics = {\n",
    "            \"total_requests\": len(self.response_times)\n",
    "        }\n",
    "        \n",
    "        if self.response_times:\n",
    "            metrics[\"average_latency_ms\"] = sum(self.response_times) / len(self.response_times)\n",
    "            metrics[\"min_latency_ms\"] = min(self.response_times)\n",
    "            metrics[\"max_latency_ms\"] = max(self.response_times)\n",
    "        \n",
    "        if self.token_usage:\n",
    "            metrics[\"average_tokens\"] = sum(self.token_usage) / len(self.token_usage)\n",
    "            metrics[\"total_tokens\"] = sum(self.token_usage)\n",
    "        \n",
    "        if self.quality_scores:\n",
    "            metrics[\"average_quality_score\"] = sum(self.quality_scores) / len(self.quality_scores)\n",
    "            metrics[\"total_feedback_count\"] = len(self.quality_scores)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def generate_insights(self) -> List[str]:\n",
    "        \"\"\"수집된 데이터를 기반으로 인사이트를 생성한다\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if self.response_times:\n",
    "            avg_latency = sum(self.response_times) / len(self.response_times)\n",
    "            if avg_latency > 5000:\n",
    "                insights.append(\"평균 응답 시간이 5초를 초과한다. 성능 최적화가 필요하다.\")\n",
    "        \n",
    "        if self.quality_scores:\n",
    "            avg_quality = sum(self.quality_scores) / len(self.quality_scores)\n",
    "            if avg_quality < 3.0:\n",
    "                insights.append(\"평균 품질 점수가 낮다. 응답 품질 개선이 필요하다.\")\n",
    "            elif avg_quality >= 4.5:\n",
    "                insights.append(\"높은 품질 점수를 유지하고 있다.\")\n",
    "        \n",
    "        if self.token_usage:\n",
    "            avg_tokens = sum(self.token_usage) / len(self.token_usage)\n",
    "            if avg_tokens > 3000:\n",
    "                insights.append(\"평균 토큰 사용량이 높다. 프롬프트 최적화를 고려해야 한다.\")\n",
    "        \n",
    "        return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. vLLM 에이전트 통합 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLLMAgent:\n",
    "    \"\"\"vLLM을 사용하는 고성능 에이전트 시스템이다\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str = \"openai/gpt-oss-20b\",\n",
    "                 base_url: str = \"http://localhost:8001/v1\",\n",
    "                 api_key: str = \"EMPTY\"):\n",
    "        \"\"\"vLLM 에이전트를 초기화하고 모든 컴포넌트를 설정한다\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        \n",
    "        # 하위 시스템 초기화\n",
    "        self.memory = ConversationMemory()\n",
    "        self.tool_manager = ToolManager()\n",
    "        self.validator = InputValidator()\n",
    "        self.recovery_strategy = RecoveryStrategy()\n",
    "        self.performance_monitor = PerformanceMonitor()\n",
    "        \n",
    "        # 시스템 메시지 설정\n",
    "        self._setup_system_message()\n",
    "    \n",
    "    def _setup_system_message(self) -> None:\n",
    "        \"\"\"도구 설명을 포함한 시스템 메시지를 설정한다\"\"\"\n",
    "        system_message = \"\"\"당신은 도구를 사용할 수 있는 유능한 AI 어시스턴트다.\n",
    "사용자의 질문에 정확하고 도움이 되는 답변을 제공한다.\n",
    "필요한 경우 제공된 도구를 활용하여 정보를 얻거나 작업을 수행한다.\"\"\"\n",
    "        self.memory.set_system_message(system_message)\n",
    "    \n",
    "    def _call_vllm(self, messages: List[Dict[str, Any]], \n",
    "                  tools: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:\n",
    "        \"\"\"vLLM API를 호출하여 응답을 받는다\"\"\"\n",
    "        params = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 2000\n",
    "        }\n",
    "        \n",
    "        if tools:\n",
    "            params[\"tools\"] = tools\n",
    "            params[\"tool_choice\"] = \"auto\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(**params)\n",
    "        \n",
    "        return {\n",
    "            \"choices\": [{\n",
    "                \"message\": {\n",
    "                    \"role\": response.choices[0].message.role,\n",
    "                    \"content\": response.choices[0].message.content,\n",
    "                    \"tool_calls\": response.choices[0].message.tool_calls\n",
    "                }\n",
    "            }],\n",
    "            \"usage\": {\n",
    "                \"total_tokens\": response.usage.total_tokens\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def run(self, user_input: str, max_iterations: int = 10) -> AgentResponse:\n",
    "        \"\"\"사용자 입력을 처리하고 응답을 생성한다\"\"\"\n",
    "        start_time = time.time()\n",
    "        operation_id = f\"op_{int(time.time() * 1000)}\"\n",
    "        \n",
    "        # 입력 검증\n",
    "        validation = self.validator.validate_message(user_input)\n",
    "        if not validation.is_valid:\n",
    "            self.recovery_strategy.log_failure(\n",
    "                \"validation_error\", \n",
    "                validation.error_message,\n",
    "                {\"input\": user_input}\n",
    "            )\n",
    "            return AgentResponse(\n",
    "                content=self.recovery_strategy.get_fallback_response(\"validation_error\"),\n",
    "                is_successful=False,\n",
    "                error_message=validation.error_message\n",
    "            )\n",
    "        \n",
    "        # 사용자 메시지 추가\n",
    "        self.memory.add_message(\"user\", user_input)\n",
    "        \n",
    "        tool_calls_made = []\n",
    "        total_tokens = 0\n",
    "        \n",
    "        # 반복적으로 모델 호출 및 도구 실행\n",
    "        for iteration in range(max_iterations):\n",
    "            messages = self.memory.get_messages()\n",
    "            tools = self.tool_manager.get_tool_schemas() if self.tool_manager.tools else None\n",
    "            \n",
    "            response = self._call_vllm(messages, tools)\n",
    "            \n",
    "            # 응답 검증\n",
    "            validation = self.validator.validate_response(response)\n",
    "            if not validation.is_valid:\n",
    "                if self.recovery_strategy.should_retry(operation_id):\n",
    "                    self.recovery_strategy.record_retry(operation_id)\n",
    "                    time.sleep(self.recovery_strategy.retry_delay)\n",
    "                    continue\n",
    "                return AgentResponse(\n",
    "                    content=self.recovery_strategy.get_fallback_response(\"api_error\"),\n",
    "                    is_successful=False,\n",
    "                    error_message=validation.error_message\n",
    "                )\n",
    "            \n",
    "            message = response[\"choices\"][0][\"message\"]\n",
    "            total_tokens += response[\"usage\"][\"total_tokens\"]\n",
    "            \n",
    "            # 도구 호출이 있는 경우\n",
    "            if message.get(\"tool_calls\"):\n",
    "                tool_calls = message[\"tool_calls\"]\n",
    "                \n",
    "                # 어시스턴트 메시지 저장\n",
    "                self.memory.add_message(\n",
    "                    \"assistant\",\n",
    "                    content=message.get(\"content\"),\n",
    "                    tool_calls=[{\n",
    "                        \"id\": tc.id,\n",
    "                        \"type\": tc.type,\n",
    "                        \"function\": {\n",
    "                            \"name\": tc.function.name,\n",
    "                            \"arguments\": tc.function.arguments\n",
    "                        }\n",
    "                    } for tc in tool_calls]\n",
    "                )\n",
    "                \n",
    "                # 각 도구 호출 실행\n",
    "                for tool_call in tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    tool = self.tool_manager.get_tool(function_name)\n",
    "                    \n",
    "                    # 도구 인자 검증\n",
    "                    arg_validation = self.validator.validate_tool_arguments(tool, function_args)\n",
    "                    if not arg_validation.is_valid:\n",
    "                        tool_result = f\"오류: {arg_validation.error_message}\"\n",
    "                    else:\n",
    "                        tool_result = self.tool_manager.execute_tool(function_name, function_args)\n",
    "                    \n",
    "                    tool_calls_made.append({\n",
    "                        \"tool\": function_name,\n",
    "                        \"arguments\": function_args,\n",
    "                        \"result\": tool_result\n",
    "                    })\n",
    "                    \n",
    "                    # 도구 실행 결과를 메모리에 추가\n",
    "                    self.memory.add_message(\n",
    "                        \"tool\",\n",
    "                        content=tool_result,\n",
    "                        tool_call_id=tool_call.id,\n",
    "                        name=function_name\n",
    "                    )\n",
    "            else:\n",
    "                # 일반 응답인 경우 종료\n",
    "                content = message.get(\"content\", \"\")\n",
    "                self.memory.add_message(\"assistant\", content)\n",
    "                \n",
    "                latency_ms = (time.time() - start_time) * 1000\n",
    "                self.performance_monitor.record_response(latency_ms, total_tokens)\n",
    "                self.recovery_strategy.reset_operation(operation_id)\n",
    "                \n",
    "                return AgentResponse(\n",
    "                    content=content,\n",
    "                    tool_calls=tool_calls_made if tool_calls_made else None,\n",
    "                    total_tokens=total_tokens,\n",
    "                    latency_ms=latency_ms,\n",
    "                    is_successful=True\n",
    "                )\n",
    "        \n",
    "        # 최대 반복 도달\n",
    "        latency_ms = (time.time() - start_time) * 1000\n",
    "        return AgentResponse(\n",
    "            content=\"최대 반복 횟수에 도달했다. 현재까지의 결과를 반환한다.\",\n",
    "            tool_calls=tool_calls_made if tool_calls_made else None,\n",
    "            total_tokens=total_tokens,\n",
    "            latency_ms=latency_ms,\n",
    "            is_successful=True\n",
    "        )\n",
    "    \n",
    "    def add_feedback(self, query: str, response: str, rating: float, comment: str = \"\") -> None:\n",
    "        \"\"\"사용자 피드백을 추가한다\"\"\"\n",
    "        self.performance_monitor.add_user_feedback(query, response, rating, comment)\n",
    "    \n",
    "    def get_agent_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"에이전트의 전체 상태를 반환한다\"\"\"\n",
    "        return {\n",
    "            \"memory_stats\": self.memory.get_statistics(),\n",
    "            \"tool_stats\": self.tool_manager.get_execution_statistics(),\n",
    "            \"recovery_stats\": self.recovery_strategy.get_recovery_statistics(),\n",
    "            \"performance_metrics\": self.performance_monitor.get_performance_metrics(),\n",
    "            \"insights\": self.performance_monitor.generate_insights()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 도구 등록 및 에이전트 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM 에이전트가 초기화되었다\n",
      "등록된 도구: ['get_current_time', 'calculate_advanced', 'query_knowledge_base', 'execute_database_query']\n"
     ]
    }
   ],
   "source": [
    "# vLLM 에이전트 초기화\n",
    "agent = VLLMAgent(\n",
    "    model_name=\"openai/gpt-oss-20b\",\n",
    "    base_url=\"http://localhost:8001/v1\"\n",
    ")\n",
    "\n",
    "# 시간 조회 도구 등록\n",
    "time_tool = ToolDefinition(\n",
    "    type=\"function\",\n",
    "    function=FunctionDefinition(\n",
    "        name=\"get_current_time\",\n",
    "        description=\"현재 시간을 조회한다\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"timezone\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"시간대 (예: UTC, KST)\",\n",
    "                    \"enum\": [\"UTC\", \"KST\", \"EST\", \"PST\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    ),\n",
    "    callable=get_current_time\n",
    ")\n",
    "agent.tool_manager.register_tool(time_tool)\n",
    "\n",
    "# 계산기 도구 등록\n",
    "calculator_tool = ToolDefinition(\n",
    "    type=\"function\",\n",
    "    function=FunctionDefinition(\n",
    "        name=\"calculate_advanced\",\n",
    "        description=\"복잡한 수학 표현식을 계산한다\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"계산할 수학 표현식 (예: '2 + 3 * 4')\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    ),\n",
    "    callable=calculate_advanced\n",
    ")\n",
    "agent.tool_manager.register_tool(calculator_tool)\n",
    "\n",
    "# 지식 베이스 조회 도구 등록\n",
    "knowledge_tool = ToolDefinition(\n",
    "    type=\"function\",\n",
    "    function=FunctionDefinition(\n",
    "        name=\"query_knowledge_base\",\n",
    "        description=\"지식 베이스에서 정보를 검색한다\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"검색할 주제\"\n",
    "                },\n",
    "                \"detail_level\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"상세 수준\",\n",
    "                    \"enum\": [\"low\", \"medium\", \"high\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    ),\n",
    "    callable=query_knowledge_base\n",
    ")\n",
    "agent.tool_manager.register_tool(knowledge_tool)\n",
    "\n",
    "# 데이터베이스 쿼리 도구 등록\n",
    "db_tool = ToolDefinition(\n",
    "    type=\"function\",\n",
    "    function=FunctionDefinition(\n",
    "        name=\"execute_database_query\",\n",
    "        description=\"데이터베이스 쿼리를 실행한다\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"실행할 SQL 쿼리\"\n",
    "                },\n",
    "                \"limit\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"결과 개수 제한\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    ),\n",
    "    callable=execute_database_query\n",
    ")\n",
    "agent.tool_manager.register_tool(db_tool)\n",
    "\n",
    "print(\"vLLM 에이전트가 초기화되었다\")\n",
    "print(f\"등록된 도구: {list(agent.tool_manager.tools.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 에이전트 실행 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예제 1: 일반 대화 ===\n",
      "응답: 안녕하세요! vLLM은 **GPU 메모리와 연산 효율을 극대화한 대형 언어 모델(LLM) 추론 프레임워크**입니다.\n",
      "\n",
      "- **핵심 아이디어**  \n",
      "  - **동적 배치(Dynamic batching)**: 실시간 요청을 작은 배치로 묶어 GPU 사용률을 높입니다.  \n",
      "  - **KV 캐시 공유(Cache sharing)**: 같은 프롬프트를 가진 요청은 KV 캐시를 공유해 메모리 사용량을 줄이고 속도를 끌어올립니다.  \n",
      "  - **삼각형 행렬 분산(Tensor parallelism)**: 모델을 여러 GPU에 나누어 파라미터를 분산시켜 대형 모델도 한 대의 GPU에서 실행 가능하도록 합니다.\n",
      "\n",
      "- **주요 특징**  \n",
      "  - **높은 처리량**: 동일한 하드웨어에서도 기존 라이브러리보다 2~3배 빠른 추론 속도 제공.  \n",
      "  - **저렴한 비용**: 메모리 효율 덕분에 GPU 수를 줄여 비용 절감.  \n",
      "  - **간단한 API**: Hugging Face Transformers와 호환되는 `LLMEngine` 인터페이스로 바로 사용 가능.  \n",
      "  - **멀티-모델 지원**: 하나의 GPU에서 여러 모델을 동시에 서비스할 수 있는 “모델 스위칭” 기능 제공.\n",
      "\n",
      "- **사용 사례**  \n",
      "  - 대규모 챗봇, 문서 생성, 번역 서비스 등 실시간 반응이 필요한 애플리케이션에 적합합니다.  \n",
      "  - 연구실이나 기업이 자체 LLM을 빠르게 프로토타이핑하거나 운영 환경에 배포할 때 활용됩니다.\n",
      "\n",
      "간단히 말해, vLLM은 **GPU 리소스를 최대한 활용해 LLM 추론을 빠르고 비용 효율적으로** 만들어 주는 도구입니다. 필요하면 더 깊이 들어가서 구현 예시나 성능 비교도 알려드릴게요!\n",
      "토큰 사용량: 875\n",
      "지연 시간: 2502.49ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 1: 일반 대화\n",
    "print(\"=== 예제 1: 일반 대화 ===\")\n",
    "response = agent.run(\"안녕하세요! vLLM에 대해 간단히 설명해주세요.\")\n",
    "print(f\"응답: {response.content}\")\n",
    "print(f\"토큰 사용량: {response.total_tokens}\")\n",
    "print(f\"지연 시간: {response.latency_ms:.2f}ms\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예제 2: 계산기 도구 사용 ===\n",
      "응답: (15 + 25) × 3 – 10 = **110**\n",
      "도구 호출: None\n",
      "지연 시간: 414.47ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 2: 도구 사용 - 계산기\n",
    "print(\"=== 예제 2: 계산기 도구 사용 ===\")\n",
    "response = agent.run(\"(15 + 25) * 3 - 10을 계산해주세요\")\n",
    "print(f\"응답: {response.content}\")\n",
    "print(f\"도구 호출: {response.tool_calls}\")\n",
    "print(f\"지연 시간: {response.latency_ms:.2f}ms\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예제 3: 시간 조회 도구 사용 ===\n",
      "응답: {\"timezone\":\"KST\"}\n",
      "도구 호출: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 3: 도구 사용 - 시간 조회\n",
    "print(\"=== 예제 3: 시간 조회 도구 사용 ===\")\n",
    "response = agent.run(\"현재 KST 시간을 알려주세요\")\n",
    "print(f\"응답: {response.content}\")\n",
    "print(f\"도구 호출: {response.tool_calls}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예제 4: 복합 도구 사용 ===\n",
      "응답: {\"topic\":\"vLLM\",\"detail_level\":\"medium\"}\n",
      "도구 호출 수: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 4: 복합 도구 사용\n",
    "print(\"=== 예제 4: 복합 도구 사용 ===\")\n",
    "response = agent.run(\"vLLM에 대한 정보를 검색하고, 그 결과를 요약해주세요\")\n",
    "print(f\"응답: {response.content}\")\n",
    "print(f\"도구 호출 수: {len(response.tool_calls) if response.tool_calls else 0}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예제 5: 피드백 추가 ===\n",
      "피드백이 추가되었다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 5: 피드백 추가\n",
    "print(\"=== 예제 5: 피드백 추가 ===\")\n",
    "query = \"Python에 대한 정보를 알려주세요\"\n",
    "response = agent.run(query)\n",
    "agent.add_feedback(query, response.content, rating=4.5, comment=\"매우 상세하고 정확한 답변이다\")\n",
    "print(f\"피드백이 추가되었다\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 성능 모니터링 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 성능 메트릭 ===\n",
      "\n",
      "메모리 통계:\n",
      "  total_messages: 10\n",
      "  role_distribution: {'user': 5, 'assistant': 5}\n",
      "  has_system_message: True\n",
      "\n",
      "도구 실행 통계:\n",
      "  total_executions: 0\n",
      "\n",
      "성능 메트릭:\n",
      "  total_requests: 5\n",
      "  average_latency_ms: 1397.0731735229492\n",
      "  min_latency_ms: 264.71614837646484\n",
      "  max_latency_ms: 3445.158004760742\n",
      "  average_tokens: 1060.4\n",
      "  total_tokens: 5302\n",
      "  average_quality_score: 4.5\n",
      "  total_feedback_count: 1\n",
      "\n",
      "인사이트:\n",
      "  - 높은 품질 점수를 유지하고 있다.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 성능 메트릭 ===\")\n",
    "status = agent.get_agent_status()\n",
    "\n",
    "print(\"\\n메모리 통계:\")\n",
    "for key, value in status[\"memory_stats\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n도구 실행 통계:\")\n",
    "for key, value in status[\"tool_stats\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n성능 메트릭:\")\n",
    "for key, value in status[\"performance_metrics\"].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n인사이트:\")\n",
    "for insight in status[\"insights\"]:\n",
    "    print(f\"  - {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 메모리 관리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 메모리 관리 테스트 ===\n",
      "응답 1: 안녕하세요, 박지민님!  \n",
      "데이터 과학자이시라니, 정말 멋지죠. vLLM, Python, 혹은 머신러닝, 통계, 데이터 시각화 등 어떤 주제든 궁금한 점이 있으면 언제든 물어보세요. 도와드릴게요!\n",
      "응답 2: 당신의 직업은 **데이터 과학자**입니다.\n",
      "응답 3: 안녕하세요! 저는 박지민입니다. 데이터 과학자로서, 빅데이터와 머신러닝을 활용해 인사이트를 도출하고 비즈니스 가치를 창출하는 일을 하고 있습니다. 앞으로도 새로운 데이터 도전과 학습을 즐기며 성장해 나가겠습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 메모리 관리 테스트 ===\")\n",
    "\n",
    "# 첫 번째 대화\n",
    "response1 = agent.run(\"제 이름은 박지민이고, 데이터 과학자입니다\")\n",
    "print(f\"응답 1: {response1.content}\")\n",
    "\n",
    "# 두 번째 대화 - 이전 컨텍스트 참조\n",
    "response2 = agent.run(\"제 직업이 무엇이었죠?\")\n",
    "print(f\"응답 2: {response2.content}\")\n",
    "\n",
    "# 세 번째 대화 - 복합 질문\n",
    "response3 = agent.run(\"제 이름과 직업을 활용해서 간단한 자기소개를 작성해주세요\")\n",
    "print(f\"응답 3: {response3.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Recovery 시스템 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recovery 시스템 테스트 ===\n",
      "빈 입력 응답: 입력 검증에 실패했다. 올바른 형식으로 다시 질문해 달라.\n",
      "성공 여부: False\n",
      "오류 메시지: 메시지가 비어있다\n",
      "\n",
      "복구 통계: {'total_failures': 1, 'error_distribution': {'validation_error': 1}, 'active_retries': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Recovery 시스템 테스트 ===\")\n",
    "\n",
    "# 빈 입력 테스트\n",
    "response = agent.run(\"\")\n",
    "print(f\"빈 입력 응답: {response.content}\")\n",
    "print(f\"성공 여부: {response.is_successful}\")\n",
    "print(f\"오류 메시지: {response.error_message}\")\n",
    "\n",
    "# 복구 통계 확인\n",
    "recovery_stats = agent.recovery_strategy.get_recovery_statistics()\n",
    "print(f\"\\n복구 통계: {recovery_stats}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
